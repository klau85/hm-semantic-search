{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-17T14:31:01.254065Z",
     "start_time": "2025-06-17T14:31:01.202476Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_milvus import Milvus\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import torch\n",
    "from typing import List\n",
    "import math\n",
    "import os\n"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:31:03.411530Z",
     "start_time": "2025-06-17T14:31:03.377614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(torch.version.cuda)  # CUDA version PyTorch was built with\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(torch.backends.cudnn.version())  # cuDNN version\n",
    "print(torch.cuda.get_device_name(0))  # GPU name\n",
    "print(torch.__version__)  # PyTorch version\n"
   ],
   "id": "48509009476e9054",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n",
      "CUDA available: True\n",
      "90100\n",
      "NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "2.7.1+cu118\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:31:06.140465Z",
     "start_time": "2025-06-17T14:31:06.111833Z"
    }
   },
   "cell_type": "code",
   "source": "load_dotenv()",
   "id": "c75705f6f4f8d06f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:31:06.706635Z",
     "start_time": "2025-06-17T14:31:06.699186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ],
   "id": "54c43dd9c4862c20",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:35:16.615116Z",
     "start_time": "2025-06-17T14:35:16.377105Z"
    }
   },
   "cell_type": "code",
   "source": "articles = pd.read_csv('data/articles_full_desc.csv', dtype={'article_id': str})",
   "id": "708251fa3d1d51e4",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:35:25.331625Z",
     "start_time": "2025-06-17T14:35:25.168526Z"
    }
   },
   "cell_type": "code",
   "source": "articles['full_description'].to_csv('data/full_desc.txt', index=False, sep='\\n', header=False, encoding='utf-8')",
   "id": "9e2fc4a562905c39",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:45:29.191110Z",
     "start_time": "2025-06-17T14:45:28.015857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loader = DataFrameLoader(articles[['article_id', 'full_description']], page_content_column='full_description')\n",
    "docs = loader.load()\n"
   ],
   "id": "720f5599c651558a",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:45:32.933182Z",
     "start_time": "2025-06-17T14:45:32.927815Z"
    }
   },
   "cell_type": "code",
   "source": "docs[2000]",
   "id": "7fe872449becd23d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'article_id': '0808866006'}, page_content='0808866006 Sarah Low BB of type Sneakers from group Shoes and section Kids & Baby Shoes. Product color is White and perceived color is Light. Trainers in imitation leather with a padded edge, lacing at the front and a loop at the back. Mesh linings and insoles and patterned soles.')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:45:42.750260Z",
     "start_time": "2025-06-17T14:45:42.310632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# embeddings = HuggingFaceEmbeddings(\n",
    "#     model_name=os.getenv('HUGGING_FACE_EMBEDDING'),\n",
    "#     model_kwargs={\n",
    "#         'device': device\n",
    "#     }\n",
    "# )\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ],
   "id": "b55f2af2835d1c13",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:45:48.611800Z",
     "start_time": "2025-06-17T14:45:48.606893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def batch_import_to_milvus(documents: List, embeddings, batch_size: int = 100, **milvus_args):\n",
    "    # Initialize Milvus with first batch to create collection\n",
    "    total_batches = math.ceil(len(documents[batch_size:]) / batch_size)\n",
    "    first_batch = documents[:batch_size]\n",
    "    print(f\"Processing batch 1/{total_batches+1}\")\n",
    "    db = Milvus.from_documents(\n",
    "        documents=first_batch,\n",
    "        embedding=embeddings,\n",
    "        **milvus_args\n",
    "    )\n",
    "\n",
    "    # Process remaining documents in batches\n",
    "    for i in range(total_batches):\n",
    "        start_idx = i * batch_size + batch_size  # Add batch_size because we already processed first batch\n",
    "        end_idx = start_idx + batch_size\n",
    "        batch = documents[start_idx:end_idx]\n",
    "        if batch:\n",
    "            print(f\"Processing batch {i+2}/{total_batches+1}\")  # +2 because we already did first batch\n",
    "            db.add_documents(documents=batch)\n",
    "\n",
    "    return db"
   ],
   "id": "c0efb787763544a0",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:49:26.110308Z",
     "start_time": "2025-06-17T14:46:11.338307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Usage\n",
    "db_articles = batch_import_to_milvus(\n",
    "    documents=docs,\n",
    "    embeddings=embeddings,\n",
    "    batch_size=300,  # Adjust this based on your needs and memory constraints\n",
    "    collection_name=os.getenv('MILVIUS_COLLECTION'),\n",
    "    connection_args={\n",
    "        \"uri\": os.getenv('ZILLIZ_CLOUD_URI'),\n",
    "        \"token\": os.getenv('ZILLIZ_CLOUD_API_KEY'),\n",
    "        \"secure\": True,\n",
    "    },\n",
    "    auto_id=True,\n",
    "    drop_old=True,\n",
    ")\n"
   ],
   "id": "e8bfadc677d711b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 17:46:11,708 [DEBUG][_create_connection]: Created new connection using: e70470a41d194f84b221d6afc7bf0b4a (async_milvus_client.py:599)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2/84\n",
      "Processing batch 3/84\n",
      "Processing batch 4/84\n",
      "Processing batch 5/84\n",
      "Processing batch 6/84\n",
      "Processing batch 7/84\n",
      "Processing batch 8/84\n",
      "Processing batch 9/84\n",
      "Processing batch 10/84\n",
      "Processing batch 11/84\n",
      "Processing batch 12/84\n",
      "Processing batch 13/84\n",
      "Processing batch 14/84\n",
      "Processing batch 15/84\n",
      "Processing batch 16/84\n",
      "Processing batch 17/84\n",
      "Processing batch 18/84\n",
      "Processing batch 19/84\n",
      "Processing batch 20/84\n",
      "Processing batch 21/84\n",
      "Processing batch 22/84\n",
      "Processing batch 23/84\n",
      "Processing batch 24/84\n",
      "Processing batch 25/84\n",
      "Processing batch 26/84\n",
      "Processing batch 27/84\n",
      "Processing batch 28/84\n",
      "Processing batch 29/84\n",
      "Processing batch 30/84\n",
      "Processing batch 31/84\n",
      "Processing batch 32/84\n",
      "Processing batch 33/84\n",
      "Processing batch 34/84\n",
      "Processing batch 35/84\n",
      "Processing batch 36/84\n",
      "Processing batch 37/84\n",
      "Processing batch 38/84\n",
      "Processing batch 39/84\n",
      "Processing batch 40/84\n",
      "Processing batch 41/84\n",
      "Processing batch 42/84\n",
      "Processing batch 43/84\n",
      "Processing batch 44/84\n",
      "Processing batch 45/84\n",
      "Processing batch 46/84\n",
      "Processing batch 47/84\n",
      "Processing batch 48/84\n",
      "Processing batch 49/84\n",
      "Processing batch 50/84\n",
      "Processing batch 51/84\n",
      "Processing batch 52/84\n",
      "Processing batch 53/84\n",
      "Processing batch 54/84\n",
      "Processing batch 55/84\n",
      "Processing batch 56/84\n",
      "Processing batch 57/84\n",
      "Processing batch 58/84\n",
      "Processing batch 59/84\n",
      "Processing batch 60/84\n",
      "Processing batch 61/84\n",
      "Processing batch 62/84\n",
      "Processing batch 63/84\n",
      "Processing batch 64/84\n",
      "Processing batch 65/84\n",
      "Processing batch 66/84\n",
      "Processing batch 67/84\n",
      "Processing batch 68/84\n",
      "Processing batch 69/84\n",
      "Processing batch 70/84\n",
      "Processing batch 71/84\n",
      "Processing batch 72/84\n",
      "Processing batch 73/84\n",
      "Processing batch 74/84\n",
      "Processing batch 75/84\n",
      "Processing batch 76/84\n",
      "Processing batch 77/84\n",
      "Processing batch 78/84\n",
      "Processing batch 79/84\n",
      "Processing batch 80/84\n",
      "Processing batch 81/84\n",
      "Processing batch 82/84\n",
      "Processing batch 83/84\n",
      "Processing batch 84/84\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:49:26.697375Z",
     "start_time": "2025-06-17T14:49:26.142378Z"
    }
   },
   "cell_type": "code",
   "source": "recs = db_articles.similarity_search_with_score('white shoes for women', k=10)",
   "id": "16b5cfa522d973ff",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T15:05:58.874301Z",
     "start_time": "2025-06-17T15:05:58.868088Z"
    }
   },
   "cell_type": "code",
   "source": "recs[0][0]",
   "id": "eb9f5dcc26109b44",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'article_id': '0805095005', 'pk': 458312174353380081}, page_content='0805095005 Theresa Loafer of type Ballerinas from group Shoes and section Womens Shoes. Product color is White and perceived color is Light. Loafers in imitation leather with a decorative seam at the front and metal buckle at the top. Satin linings and imitation leather insoles. Heel approx. 1.8 cm.')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e64b9948987c3f4a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
